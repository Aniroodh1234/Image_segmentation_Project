{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Segmentation using Watershed Algorithm\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project implements the **Watershed Algorithm**, a powerful morphology-based technique for separating touching or overlapping objects in an image. The algorithm treats pixel intensities as a topographic surface and finds watershed lines that divide different regions, making it particularly effective for segmenting objects that are close together or in contact.\n",
        "\n",
        "---\n",
        "\n",
        "## What is the Watershed Algorithm?\n",
        "\n",
        "The **Watershed Algorithm** is inspired by geographical watersheds:\n",
        "\n",
        "### Topographic Analogy:\n",
        "Imagine the grayscale image as a topographic relief (landscape):\n",
        "- **Pixel intensity** = Altitude/Elevation\n",
        "- **Dark regions** (low intensity) = Valleys\n",
        "- **Bright regions** (high intensity) = Mountains\n",
        "- **Gradient** = Slopes\n",
        "\n",
        "### The Flooding Process:\n",
        "1. Water is poured into each valley (local minimum)\n",
        "2. Water rises and fills the basins\n",
        "3. When water from different basins meets, a \"dam\" (watershed line) is built\n",
        "4. These watershed lines become the segmentation boundaries\n",
        "\n",
        "---\n",
        "\n",
        "## Why Watershed for Object Separation?\n",
        "\n",
        "### The Problem:\n",
        "- **Touching objects** appear connected in the image\n",
        "- **Overlapping objects** are difficult to separate\n",
        "- **Traditional thresholding** treats connected objects as one\n",
        "\n",
        "### The Solution:\n",
        "- Watershed identifies **natural boundaries** between objects\n",
        "- Creates **separation lines** even for touching objects\n",
        "- Works well when objects have **similar intensities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffFRQp8VPdJV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sC3f4NdPea0"
      },
      "outputs": [],
      "source": [
        "image_folder = \"Images\"\n",
        "\n",
        "# List all images\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "# Display original images\n",
        "for img_file in image_files:\n",
        "    img_path = os.path.join(image_folder, img_file)\n",
        "    img = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(f\"Original Image: {img_file}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algorithm Pipeline\n",
        "\n",
        "Our implementation follows these key steps:\n",
        "\n",
        "### 1. **Grayscale Conversion**\n",
        "```python\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "```\n",
        "- Converts RGB to single-channel intensity image\n",
        "- Simplifies processing while retaining structure\n",
        "\n",
        "### 2. **Otsu's Thresholding**\n",
        "```python\n",
        "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "```\n",
        "\n",
        "**What is Otsu's Method?**\n",
        "- **Automatic threshold selection**: No manual threshold needed\n",
        "- **Optimal threshold**: Minimizes intra-class variance\n",
        "- **THRESH_BINARY_INV**: Inverts result (objects white, background black)\n",
        "- **Purpose**: Creates binary mask separating foreground from background\n",
        "\n",
        "**Why Invert?**\n",
        "- Most images have dark objects on light background\n",
        "- Inversion makes objects white (foreground) for easier processing\n",
        "\n",
        "### 3. **Morphological Opening (Noise Removal)**\n",
        "```python\n",
        "kernel = np.ones((3,3), np.uint8)\n",
        "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "```\n",
        "\n",
        "**What is Morphological Opening?**\n",
        "- **Opening** = Erosion followed by Dilation\n",
        "- **Erosion**: Shrinks objects, removes small noise\n",
        "- **Dilation**: Expands objects back to original size\n",
        "\n",
        "**Effect:**\n",
        "- Removes salt-and-pepper noise\n",
        "- Smooths object boundaries\n",
        "- Eliminates small spurious regions\n",
        "- Preserves object size and shape\n",
        "\n",
        "### 4. **Sure Background Area**\n",
        "```python\n",
        "sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "```\n",
        "\n",
        "**Purpose:**\n",
        "- Expands objects to include surrounding pixels\n",
        "- Everything outside dilated regions is **definitely background**\n",
        "- Creates a confident background mask\n",
        "\n",
        "### 5. **Distance Transform**\n",
        "```python\n",
        "dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "```\n",
        "\n",
        "**What is Distance Transform?**\n",
        "- Calculates distance of each foreground pixel to nearest background pixel\n",
        "- **High values**: Center of objects (far from edges)\n",
        "- **Low values**: Near object boundaries\n",
        "\n",
        "**Visual Representation:**\n",
        "- Peaks at object centers\n",
        "- Valleys at object boundaries\n",
        "- Creates a topographic map of the objects\n",
        "\n",
        "**Distance Type: DIST_L2**\n",
        "- L2 = Euclidean distance\n",
        "- Most accurate distance metric\n",
        "- Formula: √[(x₁-x₂)² + (y₁-y₂)²]\n",
        "\n",
        "### 6. **Sure Foreground Area**\n",
        "```python\n",
        "ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)\n",
        "```\n",
        "\n",
        "**Strategy:**\n",
        "- Take pixels with distance > 70% of maximum distance\n",
        "- These are **definitely object centers** (far from boundaries)\n",
        "- Creates seeds for watershed algorithm\n",
        "\n",
        "**Why 0.7 (70%)?**\n",
        "- Conservative estimate ensuring we're inside objects\n",
        "- Avoids including boundary pixels\n",
        "- Can be adjusted: Higher = more conservative, Lower = more aggressive\n",
        "\n",
        "### 7. **Unknown Region**\n",
        "```python\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "```\n",
        "\n",
        "**Three Regions Created:**\n",
        "1. **Sure Background**: Definitely not object (black in sure_bg)\n",
        "2. **Sure Foreground**: Definitely object centers (white in sure_fg)\n",
        "3. **Unknown Region**: Boundaries and uncertain areas\n",
        "\n",
        "**The unknown region is where watershed will find boundaries!**\n",
        "\n",
        "### 8. **Marker Labeling**\n",
        "```python\n",
        "ret, markers = cv2.connectedComponents(sure_fg)\n",
        "markers = markers + 1\n",
        "markers[unknown==255] = 0\n",
        "```\n",
        "\n",
        "**Connected Components:**\n",
        "- Assigns unique label to each separate object\n",
        "- Labels: 0 (background), 1, 2, 3... (objects)\n",
        "\n",
        "**Marker Adjustment:**\n",
        "- Add 1 to all labels (background becomes 1, objects become 2, 3, 4...)\n",
        "- Set unknown region to 0\n",
        "- **Why?** Watershed treats 0 as unknown, >0 as known regions\n",
        "\n",
        "\n",
        "### 9. **Boundary Visualization**\n",
        "```python\n",
        "img_rgb[markers_ws == -1] = [255,0,0]  # Red boundaries\n",
        "```\n",
        "- Watershed lines (value -1) are colored red\n",
        "- Creates clear visual separation between objects\n",
        "\n",
        "---\n",
        "\n",
        "## Understanding the Results\n",
        "\n",
        "### What the Algorithm Produces:\n",
        "\n",
        "1. **Segmented Regions**: Each object has a unique marker value\n",
        "2. **Boundary Lines**: Red lines (-1 markers) separate objects\n",
        "3. **Object Separation**: Touching objects are clearly separated\n",
        "\n",
        "### Key Observations:\n",
        "\n",
        "**Successful Segmentation Indicators:**\n",
        "- Clear red boundaries between objects\n",
        "- Each distinct object has different marker value\n",
        "- Boundaries follow natural object edges\n",
        "- Minimal over-segmentation (too many regions)\n",
        "- Minimal under-segmentation (merged objects)\n",
        "\n",
        "**Common Issues:**\n",
        "- **Over-segmentation**: Too many regions (tune threshold in step 6)\n",
        "- **Under-segmentation**: Objects not separated (adjust morphological operations)\n",
        "- **Irregular boundaries**: Noisy input image (increase opening iterations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08XWNnxDPhKE"
      },
      "outputs": [],
      "source": [
        "def watershed_segmentation(image_path):\n",
        "    # Step 1: Read image\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Step 2: Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Step 3: Apply threshold to get binary image\n",
        "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Step 4: Noise removal using morphological opening\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "\n",
        "    # Step 5: Sure background area (dilate)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Step 6: Sure foreground area (distance transform)\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Step 7: Unknown region (subtract foreground from background)\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Step 8: Marker labelling\n",
        "    ret, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown==255] = 0\n",
        "\n",
        "    # Step 9: Apply watershed\n",
        "    markers_ws = cv2.watershed(img, markers)\n",
        "\n",
        "    # Step 10: Mark boundaries in red\n",
        "    img_rgb[markers_ws == -1] = [255,0,0]  # Red boundaries\n",
        "\n",
        "    return img_rgb, markers_ws\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_MHjOZPPirF"
      },
      "outputs": [],
      "source": [
        "for img_file in image_files:\n",
        "    img_path = os.path.join(image_folder, img_file)\n",
        "    segmented_img, markers = watershed_segmentation(img_path)\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(segmented_img)\n",
        "    plt.title(\"Watershed Segmentation\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Watershed Segmentation - {img_file}\", fontsize=14)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applications\n",
        "\n",
        "1. **Medical Image Analysis**\n",
        "2. **Manufacturing and Quality Control**\n",
        "3. **Biological Research**\n",
        "4. **Document Processing**\n",
        "5. **Autonomous Systems**\n",
        "\n",
        "---\n",
        "\n",
        "## Advantages of Watershed Algorithm\n",
        "\n",
        "1. **Excellent for touching/overlapping objects**: Main strength  \n",
        "2. **Produces closed contours**: Complete object boundaries  \n",
        "3. **Considers intensity gradients**: Uses image structure  \n",
        "4. **Marker-based control**: Can guide segmentation with markers  \n",
        "5. **Topology preservation**: Maintains spatial relationships  \n",
        "6. **Works with any intensity pattern**: Not limited to specific textures\n",
        "\n",
        "---\n",
        "\n",
        "## Limitations and Challenges\n",
        "\n",
        "1. **Over-segmentation prone**: May create too many regions without proper markers  \n",
        "2. **Sensitive to noise**: Noise can create false minima  \n",
        "3. **Requires preprocessing**: Needs good markers for best results  \n",
        "4. **Computation intensive**: More complex than simple thresholding  \n",
        "5. **Parameter tuning needed**: Distance threshold affects results  \n",
        "6. **May miss weak boundaries**: Requires sufficient gradient\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The Watershed Algorithm is a sophisticated morphology-based segmentation technique that excels at separating touching or overlapping objects. By treating the image as a topographic surface and using marker-controlled flooding, it can accurately delineate object boundaries even in challenging scenarios. Understanding each step of the pipeline—from preprocessing to marker creation to watershed application—is crucial for achieving optimal segmentation results.\n",
        "\n",
        "The algorithm's main strength lies in its ability to handle object separation, making it invaluable in fields like medical imaging, quality control, and biological research where precise object delineation is critical."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMXoKkdkOYiybtJ1HVOmhBZ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
